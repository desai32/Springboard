{"cells":[{"metadata":{},"cell_type":"markdown","source":"Code from the Kernel describing how to build a basic CNN model. Model taken from Datacamp tutorial."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport os\nfrom zipfile import ZipFile\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import img_to_array\nfrom keras.utils import np_utils\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom keras.models import Sequential\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = [] #load image data here\nlabels = [] #load the labels here from training data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_Data = pd.read_csv(\"../input/train.csv\") #load train data here from CSV file\n#train_Data.head() #confirm by viewing the first 5 rows\nid_code_Data = train_Data.id_code\ndiagnosis_Data = train_Data.diagnosis","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sampling data to plot and take a closer look at the images\ntemp_trainData = train_Data\ntemp_trainData.sort_values(by=['diagnosis'])\nsample_trainData = temp_trainData.sample(50)\nsample_trainData = sample_trainData.sort_values(by=['diagnosis'])\nsample_ids = sample_trainData['id_code']\nsample_ids = sample_ids.reset_index(drop=True)\nsample_diagnosis = sample_trainData['diagnosis']\nsample_diagnosis = sample_diagnosis.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''import numpy as np\nimport matplotlib.pyplot as plt\n\nw=10\nh=10\nfig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 5\nfor i in range(1, columns*rows +1):\n    img = np.random.randint(10, size=(h,w))\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\nplt.show()'''\nfrom matplotlib import image\nfig = plt.figure(figsize=(50, 50))\ncolumns = 5\nrows = 10\nfor i in range(1, columns*rows+1):\n    path = sample_ids[i-1] + '.png'\n    img = image.imread('../input/train_images/' + path)\n    #data = image.imread('../input/train_images/' + img)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(img)\n    #plt.xlabel(sample_diagnosis[i-1])\n    plt.title(sample_diagnosis[i-1], fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the function to prepare the images\ndef prepare_Images(label,path):\n    img=cv2.imread(path,cv2.IMREAD_COLOR)\n    img_res=cv2.resize(img,(100,100))\n    img_array = img_to_array(img_res)\n    img_array = img_array/255\n    dataset.append(img_array)\n    labels.append(str(label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for id_code,diagnosis in tqdm(zip(id_code_Data,diagnosis_Data)):\n #   path = os.path.join('../input/train_images','{}.png'.format(id_code))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for id_code,diagnosis in tqdm(zip(id_code_Data,diagnosis_Data)):\n    path = os.path.join('../input/train_images','{}.png'.format(id_code))\n    prepare_Images(diagnosis,path)\n    #print (id_code, diagnosis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert list to numpy array\nimages = np.array(dataset)\nlabel_arr = np.array(labels)\n#label_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#spliting the training data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(images,label_arr,test_size=0.20,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert to class labels categorical\ny_train = np_utils.to_categorical(y_train, num_classes=5)\ny_test = np_utils.to_categorical(y_test, num_classes=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Building the model\nmodel = Sequential()\n# First convolutional layer accepts image input\nmodel.add(Conv2D(filters=32, kernel_size=5, padding='same', activation='relu', \n                        input_shape=(100, 100, 3)))\n# Add a max pooling layer\nmodel.add(MaxPooling2D(4))\n# Add a convolutional layer\nmodel.add(Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n# Add another max pooling layer\nmodel.add(MaxPooling2D(4))\nmodel.add(Conv2D(filters=64, kernel_size=5, padding='same', activation='relu'))\n# Add another max pooling layer\n# Flatten and feed to output layer\nmodel.add(Flatten())\nmodel.add(Dense(5, activation='softmax'))\n\n# Summarize the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n#hist = model.fit(x_train,y_train,batch_size=64,epochs=10,validation_data=(x_test, y_test))\n#model.fit(x_train,y_train,batch_size=64,epochs=10)\n#pred = model.predict(x_test)\n#score = model.evaluate(x_test, y_test, batch_size=16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist = model.fit(x_train, y_train, validation_split=.2, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Obtain accuracy on test set\nscore = model.evaluate(x=x_test, \n                       y=y_test,\n                       verbose=0)\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report,confusion_matrix\nacc_score = round(accuracy_score(y_test.argmax(axis=1), pred.argmax(axis=1)),2)\nprint(acc_score)\nreport = classification_report(y_test.argmax(axis=1), pred.argmax(axis=1))\nprint(report)\nconMat = confusion_matrix(y_test.argmax(axis=1),pred.argmax(axis=1))\nprint(conMat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Any results you write to the current directory are saved as output.\ntest_df = pd.read_csv('../input/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = test_df['id_code']\ntest_Dataset = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_test_data(path):\n    img = cv2.imread(path,cv2.IMREAD_COLOR)\n    img_res = cv2.resize(img, (100,100))\n    img_array = img_to_array(img_res)\n    img_array = img_array/255\n    test_Dataset.append(img_array)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for id_code in tqdm(x):\n    path = os.path.join('../input/test_images','{}.png'.format(id_code))\n    make_test_data(path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image = np.array(test_Dataset) #convert the test image to np array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=model.predict(test_image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/sample_submission.csv')\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.diagnosis = pred\nsub_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}